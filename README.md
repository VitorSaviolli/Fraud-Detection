# ğŸ” Sistema de DetecÃ§Ã£o de Fraudes em CartÃ£o de CrÃ©dito

Sistema completo de Machine Learning para detectar fraudes em transaÃ§Ãµes de cartÃ£o de crÃ©dito, implementado desde a anÃ¡lise exploratÃ³ria atÃ© o modelo em produÃ§Ã£o.
Lembrando que o sistema foi feito para aprendizado de Machine Learning, anÃ¡lise de dados entre outras tecnologias, ou seja, o cÃ³digo inteiro foi feito inteiramente Ã  mÃ£o sem "copia e cola".

## ğŸ¯ Objetivo

Desenvolver um sistema robusto de detecÃ§Ã£o de fraudes com foco em:
- **Recall Alto (>85%)**: Capturar mÃ¡ximo de fraudes possÃ­vel
- **PrecisÃ£o Balanceada**: Minimizar falsos positivos
- **ProduÃ§Ã£o Ready**: CÃ³digo modular e reutilizÃ¡vel
- **Performance**: PrediÃ§Ãµes em tempo real

## ğŸ“Š Dataset

- **Fonte**: TransaÃ§Ãµes de cartÃ£o de crÃ©dito europeias
- **Tamanho**: 284.807 transaÃ§Ãµes
- **Desbalanceamento**: 99.83% legÃ­timas vs 0.17% fraudes (492 fraudes)
- **Features**: 
  - 28 features anÃ´nimas (V1-V28) transformadas por PCA
  - `Time`: segundos desde primeira transaÃ§Ã£o
  - `Amount`: valor da transaÃ§Ã£o
  - `Class`: 0 (legÃ­tima) ou 1 (fraude)

## ğŸ› ï¸ Stack TecnolÃ³gica

### Core
- **Python 3.14+**
- **Pandas & NumPy**: ManipulaÃ§Ã£o e anÃ¡lise de dados
- **Scikit-learn**: PrÃ©-processamento e mÃ©tricas
- **XGBoost**: Modelo de gradient boosting

### Balanceamento & Processamento
- **SMOTE (imblearn)**: Oversampling sintÃ©tico
- **StandardScaler**: NormalizaÃ§Ã£o de features
- **LabelEncoder**: Encoding de categorias

### VisualizaÃ§Ã£o & AnÃ¡lise
- **Matplotlib & Seaborn**: GrÃ¡ficos e anÃ¡lises visuais
- **Jupyter Notebook**: ExploraÃ§Ã£o interativa

### PersistÃªncia
- **Pickle**: SerializaÃ§Ã£o de modelos

## ğŸ”„ Pipeline de ML

### 1. **AnÃ¡lise ExploratÃ³ria (EDA)**
```python
notebooks/exploracao_dados.ipynb
```
- DistribuiÃ§Ã£o temporal de fraudes (0-6h, 6-12h, etc.)
- CorrelaÃ§Ã£o de features com fraudes (V14, V17 mais relevantes)
- AnÃ¡lise de valores de transaÃ§Ãµes (fraudes tendem a valores baixos)
- VisualizaÃ§Ãµes de padrÃµes e outliers

### 2. **Feature Engineering**
```python
src/fraud_detector.py â†’ create_features()
```

**Features NumÃ©ricas:**
- `Amount_log`: `np.log1p(Amount)` - reduz impacto de outliers
- `Amount_sqrt`: `âˆšAmount` - suaviza distribuiÃ§Ã£o
- `Time_hours`: conversÃ£o de segundos para horas

**Features Temporais CÃ­clicas:**
- `Time_sin`: `sin(2Ï€ Ã— Time_hours / 24)` - padrÃ£o circular diÃ¡rio
- `Time_cos`: `cos(2Ï€ Ã— Time_hours / 24)` - complemento seno

**Features de InteraÃ§Ã£o:**
- `V14_V17`: multiplicaÃ§Ã£o de features importantes
- `Amount_V14`: interaÃ§Ã£o valor Ã— V14

**Features CategÃ³ricas:**
- `Amount_category`: [Muito baixo, Baixo, MÃ©dio, Alto, Muito Alto]

### 3. **PrÃ©-processamento**
```python
src/fraud_detector.py â†’ preprocess()
```

**SequÃªncia:**
1. **Feature Engineering** (create_features)
2. **Label Encoding** (Amount_category â†’ nÃºmeros)
3. **RemoÃ§Ã£o** de features nÃ£o numÃ©ricas
4. **DivisÃ£o** treino/teste (80/20 com stratify)
5. **SMOTE** (227k legÃ­timas â†’ 227k fraudes sintÃ©ticas)
6. **StandardScaler** (mÃ©dia=0, desvio=1)

### 4. **Modelagem**

**Arquitetura XGBoost:**
```python
XGBClassifier(
    n_estimators=50,      # 50 Ã¡rvores sequenciais
    max_depth=6,          # Profundidade mÃ¡xima
    learning_rate=0.1,    # Taxa de aprendizado (10%)
    random_state=42,      # Reprodutibilidade
    eval_metric='logloss' # MÃ©trica de avaliaÃ§Ã£o
)
```

**Por que XGBoost?**
- Ensemble de Ã¡rvores que corrigem erros anteriores
- RegularizaÃ§Ã£o embutida (evita overfitting)
- Excelente para dados desbalanceados
- RÃ¡pido e eficiente

## ğŸ“ˆ Resultados

### MÃ©tricas Finais
| MÃ©trica | Valor |
|---------|-------|
| **Recall** | ~85-90% |
| **Precision** | ~28-35% |
| **F1-Score** | ~42-48% |

### InterpretaÃ§Ã£o
- âœ… **Recall Alto**: Detecta maioria das fraudes (prioridade)
- âš ï¸ **Precision Baixa**: Alguns falsos positivos (aceitÃ¡vel para fraudes)
- ğŸ’¡ **Trade-off**: Melhor bloquear fraude legÃ­tima que deixar passar fraude real

### Matriz de ConfusÃ£o (Exemplo)
```
                Pred LegÃ­tima  Pred Fraude
Real LegÃ­tima      56,800         62
Real Fraude           15          83
```
- 83/98 fraudes detectadas (84.7% recall)
- 62 clientes honestos bloqueados (falsos positivos)

## ğŸ“ Estrutura do Projeto

```
fraudcard/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ creditcard.csv          # Dataset original
â”‚   â””â”€â”€ processed/                  # (vazio - para dados processados)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploracao_dados.ipynb      # EDA completa + anÃ¡lise
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py                 # Torna src um mÃ³dulo
â”‚   â”œâ”€â”€ fraud_detector.py           # Classe principal do modelo
â”‚   â””â”€â”€ sample_transaction.py       # TransaÃ§Ã£o de exemplo
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ fraud_detector.pkl          # Modelo treinado salvo
â”‚
â”œâ”€â”€ main.py                         # Script de execuÃ§Ã£o
â”œâ”€â”€ requirements.txt                # DependÃªncias
â””â”€â”€ README.md                       # Este arquivo
```

## ğŸš€ Como Executar

### 1. **InstalaÃ§Ã£o**

```bash
# Clone o repositÃ³rio
git clone https://github.com/VitorSaviolli/Fraud-Detection.git
cd Fraud-Detection

# Instale as dependÃªncias
pip install -r requirements.txt
```

### 2. **Treinamento**

```bash
# Treina modelo, salva e testa prediÃ§Ã£o
python main.py
```

**Output esperado:**
```
Sistema de DetecÃ§Ã£o de Fraudes:
Carregando dados...
Criando features...
Separando X e y...
Dividindo treino e teste...
Aplicando SMOTE...
Normalizando...
Treinando XGBOOST...
Avaliando...
Recall 0.857 (85.7%)
Precision 0.286 (28.6%)
Modelo salvo em models/fraud_detector.pkl

Testando prediÃ§Ã£o...
Resultado: LEGÃTIMA
Probabilidade de Fraude: 0.084
Probabilidade LegÃ­tima: 0.916
```

### 3. **Usando o Modelo**

```python
from src.fraud_detector import FraudDetector

# Carrega modelo treinado
detector = FraudDetector()
detector.load_model('models/fraud_detector.pkl')

# Nova transaÃ§Ã£o
transacao = {
    'Time': 406,
    'V1': -1.359807,
    'V2': -0.072781,
    # ... V3-V28
    'Amount': 149.62
}

# PrediÃ§Ã£o
resultado = detector.predict(transacao)
print(resultado)
# {'prediction': 'LEGÃTIMA', 
#  'probability_fraud': 0.084, 
#  'probability_legit': 0.916}
```

## ğŸ” Detalhes TÃ©cnicos

### Classe FraudDetector

```python
class FraudDetector:
    def __init__(self)
    def create_features(df)      # Feature engineering
    def preprocess(df, fit)       # PrÃ©-processamento
    def train(csv_path)           # Treina modelo
    def predict(transaction)      # Prediz fraude
    def save_model(filepath)      # Salva modelo
    def load_model(filepath)      # Carrega modelo
```

### Fluxo de PrediÃ§Ã£o

```
Nova TransaÃ§Ã£o (dict)
    â†“
create_features()  â†’ Engenharia de features
    â†“
preprocess()       â†’ Label encoding + seleÃ§Ã£o
    â†“
scaler.transform() â†’ NormalizaÃ§Ã£o
    â†“
model.predict()    â†’ Classe (0 ou 1)
    â†“
model.predict_proba() â†’ Probabilidades
    â†“
return {prediction, probability_fraud, probability_legit}
```

## ğŸ“š Conceitos Aplicados

### SMOTE (Synthetic Minority Over-sampling)
- Cria fraudes sintÃ©ticas interpolando entre vizinhos
- Balanceia dataset (50/50) sem overfitting
- Melhora detecÃ§Ã£o de classe minoritÃ¡ria

### StandardScaler
- Normaliza features (mÃ©dia=0, desvio=1)
- Evita dominÃ¢ncia de features com valores altos
- Essencial para algoritmos baseados em distÃ¢ncia

### Stratified Split
- MantÃ©m proporÃ§Ã£o de classes em treino/teste
- Garante representatividade estatÃ­stica
- Essencial para dados desbalanceados

### Feature Engineering Temporal
- `sin/cos` capturam padrÃµes cÃ­clicos (horÃ¡rios)
- Melhor que features lineares para tempo
- Modelo entende que 23h estÃ¡ perto de 0h

## ğŸ“ Aprendizados

**TÃ©cnicos:**
- Tratamento de dados extremamente desbalanceados
- Feature engineering criativa com PCA
- Trade-offs entre Recall e Precision
- SerializaÃ§Ã£o e deploy de modelos ML

**Conceituais:**
- ImportÃ¢ncia de Recall em detecÃ§Ã£o de fraude
- Custo de falsos positivos vs falsos negativos
- Interpretabilidade vs Performance
- Pipeline completo de ML (EDA â†’ ProduÃ§Ã£o)


## ğŸ“„ LicenÃ§a

Este projeto Ã© open-source para fins educacionais.

---

â­ **Se este projeto te ajudou ou achou interessante, deixe uma estrela no repositÃ³rio, me ajuda bastante!**