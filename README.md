# ğŸ” DetecÃ§Ã£o de Fraudes em CartÃ£o de CrÃ©dito(NÃƒO FINALIZADO!)

Projeto de Machine Learning para detectar fraudes em transaÃ§Ãµes de cartÃ£o de crÃ©dito com foco em **maximizar o Recall (90%+)** para capturar o mÃ¡ximo de fraudes possÃ­vel.

## ğŸ¯ Objetivo
- **Recall Alto**: Detectar 90%+ das fraudes (prioridade mÃ¡xima)
- **PrecisÃ£o AceitÃ¡vel**: Minimizar falsos positivos quando possÃ­vel
- **Impacto**: Proteger clientes e reduzir perdas financeiras

## ğŸ“Š Dataset
- **Fonte**: TransaÃ§Ãµes de cartÃ£o de crÃ©dito
- **Tamanho**: 284.807 transaÃ§Ãµes
- **Classes**: Extremamente desbalanceadas (99.83% legÃ­timas, 0.17% fraudes)
- **Features**: 30 variÃ¡veis (V1-V28 + Time + Amount)

## ğŸ› ï¸ Tecnologias Utilizadas
- **Python**: Linguagem principal
- **Pandas & NumPy**: ManipulaÃ§Ã£o de dados
- **Scikit-learn**: Algoritmos de ML e mÃ©tricas
- **XGBoost**: Gradient boosting avanÃ§ado
- **SMOTE**: Balanceamento de classes
- **Matplotlib & Seaborn**: VisualizaÃ§Ã£o

## ğŸ”„ Pipeline de ML

### 1. **ExploraÃ§Ã£o de Dados (EDA)**
- AnÃ¡lise de distribuiÃ§Ãµes e padrÃµes temporais
- IdentificaÃ§Ã£o de correlaÃ§Ãµes com fraudes
- VisualizaÃ§Ã£o de outliers e valores

### 2. **Feature Engineering**
- `Amount_log`: TransformaÃ§Ã£o logarÃ­tmica do valor
- `Time_sin/cos`: Features temporais cÃ­clicas
- `V14_V17`: Features de interaÃ§Ã£o
- `Amount_category`: CategorizaÃ§Ã£o por faixas

### 3. **PrÃ©-processamento**
- **SMOTE**: Balanceamento sintÃ©tico (227k exemplos cada classe)
- **StandardScaler**: NormalizaÃ§Ã£o das features
- **Train/Test Split**: 80/20 com estratificaÃ§Ã£o

### 4. **Modelagem**
ComparaÃ§Ã£o de 3 algoritmos:
- **Logistic Regression**: Baseline linear
- **Random Forest**: Ensemble de Ã¡rvores
- **XGBoost**: Gradient boosting otimizado

## ğŸ“ˆ Resultados

| Modelo | Recall | Precision |
|--------|--------|-----------|
| Random Forest | 85.7% | 92.1% |
| XGBoost | 88.2% | 89.5% |
| Logistic Regression | 82.3% | 94.2% |

**ğŸ† Melhor modelo**: XGBoost (melhor Recall)

## ğŸ“ Estrutura do Projeto
```
capacitron_app/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ creditcard.csv
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploracao_dados.ipynb
â”œâ”€â”€ src/
â”œâ”€â”€ main.py
â””â”€â”€ README.md
```

## ğŸš€ Como Executar
1. Clone o repositÃ³rio
2. Instale as dependÃªncias: `pip install -r requirements.txt`
3. Execute o notebook: `jupyter notebook notebooks/exploracao_dados.ipynb`

## ğŸ“‹ PrÃ³ximos Passos
- [ ] OtimizaÃ§Ã£o de threshold para maximizar Recall
- [ ] Hyperparameter tuning com GridSearch
- [ ] Deploy do modelo em produÃ§Ã£o
- [ ] Monitoramento de performance

## ğŸ“ Aprendizados
Este projeto foca no **aprendizado prÃ¡tico** de ML, explorando:
- Tratamento de dados desbalanceados
- Feature engineering criativa
- Trade-offs entre Recall e Precision
- ComparaÃ§Ã£o de algoritmos de ML

---
**Autor**: Vitor  Saviolli Gonsalez